{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scene Recognition with Bag-of-Words](https://dellaert.github.io/19F-4476/proj5.html)\n",
    "For this project, you will need to report performance for two\n",
    "combinations of features / classifiers. It is suggested you code them in\n",
    "this order, as well:\n",
    "1. Tiny image features and nearest neighbor classifier\n",
    "2. Bag of sift features and nearest neighbor classifier\n",
    "\n",
    "The starter code is initialized to 'placeholder' just so that the starter\n",
    "code does not crash when run unmodified and you can get a preview of how\n",
    "results are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters, image paths and category list\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from proj5_code.utils import *\n",
    "import proj5_code.student_code as sc\n",
    "\n",
    "# Importing tests\n",
    "from proj5_unit_tests.test_student_code import (test_build_vocabulary_shape,\n",
    "    test_build_vocabulary_values, test_get_bags_of_sifts, \n",
    "    test_get_tiny_images_size, test_get_tiny_images_values, \n",
    "    test_kmeans_quantize_exact_matches, test_kmeans_quantize_noisy_continuous, \n",
    "    test_kmeans_2_classes_1d_features, test_kmeans_5_classes_2d_features,\n",
    "    test_nearest_neighbor_classify,\n",
    "    test_nearest_neighbor_classify_k, verify, test_pairwise_distances)\n",
    "\n",
    "# This is the list of categories / directories to use. The categories are\n",
    "# somewhat sorted by similarity so that the confusion matrix looks more\n",
    "# structured (indoor and then urban and then rural).\n",
    "categories = ['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office', 'Industrial', 'Suburb',\n",
    "              'InsideCity', 'TallBuilding', 'Street', 'Highway', 'OpenCountry', 'Coast',\n",
    "              'Mountain', 'Forest'];\n",
    "# This list of shortened category names is used later for visualization\n",
    "abbr_categories = ['Kit', 'Sto', 'Bed', 'Liv', 'Off', 'Ind', 'Sub',\n",
    "                   'Cty', 'Bld', 'St', 'HW', 'OC', 'Cst',\n",
    "                   'Mnt', 'For'];\n",
    "\n",
    "# Number of training examples per category to use. Max is 100. For\n",
    "# simplicity, we assume this is the number of test cases per category, as\n",
    "# well.\n",
    "num_train_per_cat = 100\n",
    "\n",
    "# This function returns lists containing the file path for each train\n",
    "# and test image, as well as lists with the label of each train and\n",
    "# test image. By default all four of these lists will have 1500 elements\n",
    "# where each element is a string.\n",
    "data_path = osp.join('..', 'data')\n",
    "# train_image_paths, test_image_paths, train_labels, test_labels = get_image_paths(data_path,\n",
    "#                                                                                  categories,\n",
    "#                                                                                  num_train_per_cat);\n",
    "train_image_arrays, test_image_arrays, train_labels, test_labels = get_image_arrays(data_path,\n",
    "                                                                                 categories,\n",
    "                                                                               num_train_per_cat)\n",
    "if len(train_image_arrays) == 0:\n",
    "    print(data_path, 'not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Tiny Image features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1a: Pairwise distances\n",
    "\n",
    "In order to perform nearest neighbor classification, we'll need a distance metric. In `pairwise_distances()` you'll be implementing a Euclidean distance method. Recall that in 2D, the Euclidean distance between two vectors $X = [x_1, x_2]$ and $Y = [y_1, y_2]$ is defined as\n",
    "\n",
    "$$dist(X, Y) = \\sqrt{(y_1 - x_1)^2 + (y_2 - x_2)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual distances [[0.         1.41421356 2.        ]]\n",
      "test distances [[0.         1.41421356 2.        ]]\n",
      "test_pairwise_distances():\u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"test_pairwise_distances():\" + verify(test_pairwise_distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1a: Represent each image with the Tiny Image feature\n",
    "\n",
    "Each function to construct features should return an N x d numpy array, where N is the number of paths passed to the function and d is the dimensionality of each image representation. See the starter code for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the TINY IMAGE representation for images\n",
      "test_get_tiny_images_size():\u001b[32m\"Correct\"\u001b[0m\n",
      "test_get_tiny_images_values():\u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Using the TINY IMAGE representation for images')\n",
    "\n",
    "train_image_feats = sc.get_tiny_images(train_image_arrays)\n",
    "test_image_feats = sc.get_tiny_images(test_image_arrays)\n",
    "\n",
    "print(\"test_get_tiny_images_size():\" + verify(test_get_tiny_images_size))\n",
    "print(\"test_get_tiny_images_values():\" + verify(test_get_tiny_images_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1b: Classify each test image by training and using the Nearest Neighbor classifier\n",
    "\n",
    "To run this cell you will need to implement the nearest neighbor classifier. See the function stub for details.\n",
    "\n",
    "Each function to classify test features will return an N element list, where N is the number of test cases and each entry is a string indicating the predicted category for each test image. Each entry in 'predicted_categories' must be one of the 15 strings in 'categories', 'train_labels', and 'test_labels'. See the starter code for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nearest_neighbor_classify()\u001b[32m\"Correct\"\u001b[0m\n",
      "test_nearest_neighbor_classify_k()\u001b[32m\"Correct\"\u001b[0m\n",
      "Using NEAREST NEIGHBOR classifier to predict test set categories\n"
     ]
    }
   ],
   "source": [
    "print(\"test_nearest_neighbor_classify()\" + verify(test_nearest_neighbor_classify))\n",
    "print(\"test_nearest_neighbor_classify_k()\" + verify(test_nearest_neighbor_classify_k))\n",
    "\n",
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1c: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You do not need to code anything in this section.)\n",
    "\n",
    "If we wanted to evaluate our recognition method properly we would train\n",
    "and test on many random splits of the data. You are not required to do so\n",
    "for this project.\n",
    "\n",
    "This function will create a confusion matrix and various image\n",
    "thumbnails each time it is called. View the confusion matrix to help interpret\n",
    "your classifier performance. Where is it making mistakes? Are the\n",
    "confusions reasonable?\n",
    "\n",
    "Interpreting your performance with 100 training examples per category:\n",
    "- accuracy  =   0 -> Your code is broken (probably not the classifier's fault! A classifier would have to be amazing to perform this badly).\n",
    "- accuracy ~= .07 -> Your performance is chance. Something is broken or you ran the starter code unchanged.\n",
    "- accuracy ~= .15 ~ .20 -> Rough performance with tiny images and nearest neighbor classifier. Performance goes up a few percentage points with K-NN instead of 1-NN.\n",
    "- accuracy ~= .20 -> Rough performance with tiny images and linear SVM classifier. The linear classifiers will have a lot of trouble trying to separate the classes and may be unstable (e.g. everything classified to one category)\n",
    "- accuracy ~= .40 ~ .50 -> Rough performance with bag of SIFT and nearest neighbor classifier. Can reach .60 with K-NN and different distance metrics.\n",
    "- accuracy ~= .60 -> You've gotten things roughly correct with bag of SIFT and a linear SVM classifier.\n",
    "- accuracy >= .70 -> You've also tuned your parameters well. E.g. number of clusters, SVM regularization, number of patches sampled when building vocabulary, size and step for dense SIFT features.\n",
    "- accuracy >= .80 -> You've added in spatial information somehow or you've added additional, complementary image features. This represents state of the art in Lazebnik et al 2006.\n",
    "- accuracy >= .85 -> You've done extremely well. This is the state of the art in the 2010 SUN database paper from fusing many  features. Don't trust this number unless you actually measure many random splits.\n",
    "- accuracy >= .90 -> You used modern deep features trained on much larger image databases.\n",
    "- accuracy >= .96 -> You can beat a human at this task. This isn't a realistic number. Some accuracy calculation is broken or your classifier is cheating and seeing the test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results(train_labels, test_labels, categories, abbr_categories,\n",
    "             predicted_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Bag of SIFT features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2a: Represent each image with the Bag of SIFT feature\n",
    "\n",
    "Now we will implement a more advanced feature set to describe our images - SIFT features! To build the SIFT vocabulary for bag of words, you will need to implement the k-means clustering algorithm and utilize it in your build vocabulary function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we have provided you with a simple visual demo on how kmeans works. No need to write any code yet, run the next cell, and play around with the slider to check the kmeans clustering process. (Credits to teaching staff from CS6601; thank you Prof. Starner!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7ff9aa41cb00>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473c6e491f804fe8be5e444a6fcee4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='i', max=10, min=1), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "K = 3\n",
    "data = np.load('../proj5_unit_tests/test_data/kmeans.npz', allow_pickle=True)\n",
    "print(data)\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "means_history = data['means']\n",
    "clusters_history = data['clu']\n",
    "\n",
    "# This is an interactive cell to see the progress of training your K-means algorithm.\n",
    "# Feel free to improve the visualization code and share it with your classmates on Piazza\n",
    "def get_cluster(i):\n",
    "    clusters = clusters_history[i] # Get the clusters from K-means' i-th iteration\n",
    "    plt.figure(None, figsize=(15,6)) # Set the plot size\n",
    "    plt.suptitle('Drag the slider to see the algorthm training progress')\n",
    "    ax1=plt.subplot(1, 2, 1)\n",
    "    ax1.set_title('K-means clsuters - step %d' % i)\n",
    "    for k in range(K):\n",
    "        plt.plot(X[clusters==k,0], X[clusters==k,1], '.')\n",
    "    # Just to get a flavour of how the data looks like\n",
    "    ax2=plt.subplot(1, 2, 2)\n",
    "    ax2.set_title('Ground truth clusters')\n",
    "    for i in np.unique(y):\n",
    "        ax2.plot(X[y==i,0],X[y==i,1],'.')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interactive(get_cluster, i=(1,len(clusters_history)-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_kmeans_2_classes_1d_features()\u001b[32m\"Correct\"\u001b[0m\n",
      "test_kmeans_5_classes_2d_features()\u001b[32m\"Correct\"\u001b[0m\n",
      "test_kmeans_2_classes_1d_features()\u001b[32m\"Correct\"\u001b[0m\n",
      "test_kmeans_5_classes_2d_features()\u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"test_kmeans_2_classes_1d_features()\" + verify(test_kmeans_2_classes_1d_features))\n",
    "print(\"test_kmeans_5_classes_2d_features()\" + verify(test_kmeans_5_classes_2d_features))\n",
    "\n",
    "print(\"test_kmeans_2_classes_1d_features()\" + verify(test_build_vocabulary_shape))\n",
    "print(\"test_kmeans_5_classes_2d_features()\" + verify(test_build_vocabulary_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new vocabulary, make sure `vocab_filename` is different than the old vocabulary, or delete the old one.\n",
    "\n",
    "**Important: note the logic for this cell: if the vocab file is present in the directory, then we'll proceed directly to getting SIFT representations; otherwise the vocab is built from scratch. The first time you run the cell, expect running time to be at least 10 minutes, as we are building the vocab as well as getting SIFT representations at the same time. Hence, make sure that you have passed all unit tests for this section before proceeding with the following cell!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BAG-OF-SIFT representation for images\n",
      "No existing visual word vocabulary found. Computing one from training images\n",
      "[array([[0.06118659, 0.        , 0.        , ..., 0.        , 0.09647984,\n",
      "        0.08659875],\n",
      "       [0.0360874 , 0.        , 0.00786328, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.11888065, 0.03959135, ..., 0.25890316, 0.11333243,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.12023977, 0.03228331, 0.        , ..., 0.        , 0.01127028,\n",
      "        0.060169  ],\n",
      "       [0.11565042, 0.        , 0.        , ..., 0.        , 0.02760134,\n",
      "        0.1192834 ],\n",
      "       [0.04124538, 0.00622796, 0.01154736, ..., 0.02269579, 0.05581092,\n",
      "        0.08503016]])\n",
      " array([[0.16269119, 0.25412104, 0.        , ..., 0.04669481, 0.02237292,\n",
      "        0.        ],\n",
      "       [0.00988195, 0.01460975, 0.        , ..., 0.01859035, 0.01146332,\n",
      "        0.00876614],\n",
      "       [0.        , 0.38795444, 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.00403498, ..., 0.0414953 , 0.04605312,\n",
      "        0.04163703],\n",
      "       [0.02322709, 0.        , 0.0258082 , ..., 0.61134304, 0.07049777,\n",
      "        0.        ],\n",
      "       [0.05645227, 0.03132867, 0.11284567, ..., 0.        , 0.01419509,\n",
      "        0.        ]])\n",
      " array([[0.        , 0.        , 0.13990884, ..., 0.        , 0.00918566,\n",
      "        0.00758704],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.22311721,\n",
      "        0.06661019],\n",
      "       [0.06034477, 0.09388424, 0.        , ..., 0.0392206 , 0.07439269,\n",
      "        0.03987338],\n",
      "       ...,\n",
      "       [0.24989625, 0.0464027 , 0.        , ..., 0.14830132, 0.14520572,\n",
      "        0.14704037],\n",
      "       [0.15400593, 0.38121145, 0.        , ..., 0.04173726, 0.12577058,\n",
      "        0.14186669],\n",
      "       [0.10524963, 0.11908751, 0.03758908, ..., 0.00905929, 0.00860648,\n",
      "        0.0537587 ]])\n",
      " ...\n",
      " array([[1.89011710e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.05198491e-01,\n",
      "        7.03201167e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.99331614e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.52708323e-01,\n",
      "        2.44870544e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        7.03201167e-02, 0.00000000e+00, 0.00000000e+00, 7.03191548e-02,\n",
      "        4.22884111e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.85716394e-01,\n",
      "        1.13465320e-01, 3.11396954e-02, 1.63445659e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.08217033e-02, 0.00000000e+00, 1.89438541e-01,\n",
      "        1.11810780e-01, 2.90875889e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 3.76836175e-02, 0.00000000e+00, 2.74446861e-01,\n",
      "        1.31796021e-01, 2.75862120e-02, 2.51252038e-02, 0.00000000e+00,\n",
      "        2.01941506e-02, 3.44680207e-02, 2.75860244e-02, 1.66451764e-01,\n",
      "        2.01068045e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.01068032e-01,\n",
      "        4.39319741e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.60413559e-01, 2.33021692e-01,\n",
      "        1.12336836e-01, 2.01941506e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 7.81838141e-02, 2.02531310e-01, 1.40416341e-01,\n",
      "        1.24394801e-01, 2.75858347e-02, 2.23272435e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 7.58901304e-02, 1.16406497e-01, 1.43023352e-01,\n",
      "        4.79794222e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.79794222e-02,\n",
      "        5.18377462e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 4.45465805e-02, 1.08589970e-01, 1.69260757e-01,\n",
      "        2.15966426e-01, 6.47618480e-02, 4.92785376e-02, 0.00000000e+00,\n",
      "        2.01941506e-02, 3.76836175e-02, 1.29640231e-01, 7.03201167e-02,\n",
      "        9.67583679e-02, 2.75860703e-02, 0.00000000e+00, 3.43220403e-02,\n",
      "        4.60650555e-02, 3.76836175e-02, 1.27057621e-01, 1.62081095e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.91103500e-03,\n",
      "        2.26788831e-02, 1.07839617e-02, 1.75159095e-03, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        3.79577528e-02, 4.74570613e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.87317382e-02, 1.35595892e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        3.79577312e-02, 4.74569059e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 2.15881066e-02, 4.25825420e-03,\n",
      "        4.23347567e-02, 1.16312848e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.41702630e-03,\n",
      "        1.42907409e-02, 3.56374373e-02, 9.11884660e-03, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.69258361e-03,\n",
      "        2.24224459e-02, 1.51894986e-02, 9.32468147e-03, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 7.67866915e-04, 7.18461099e-03,\n",
      "        1.80295144e-02, 3.30197040e-02, 2.81940586e-03, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.98959378e-02, 2.65691580e-01, 2.59255679e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.19082774e-02, 1.04451150e-02, 3.99705213e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.07082627e-02, 2.42513985e-02, 1.40921864e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.87256823e-03, 2.69258664e-03,\n",
      "        6.63912872e-03, 2.83790688e-02, 1.30372813e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.22753754e-01, 5.18606764e-01, 0.00000000e+00,\n",
      "        2.98486807e-02, 4.09084146e-02, 0.00000000e+00, 1.11385933e-02,\n",
      "        0.00000000e+00, 4.83465255e-02, 5.32910070e-01, 0.00000000e+00,\n",
      "        8.53974091e-03, 0.00000000e+00, 1.13517483e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 3.97313021e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 3.56013253e-01, 2.65441346e-02,\n",
      "        5.86706996e-02, 5.12168949e-02, 0.00000000e+00, 5.83146863e-03,\n",
      "        7.86392993e-03, 8.91790491e-03, 9.71686700e-02, 1.28395523e-01],\n",
      "       [0.00000000e+00, 4.90172868e-01, 2.28651387e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 4.84217849e-01, 1.25809649e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.29935251e-01, 2.05816802e-01, 2.36658853e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 2.35615346e-01, 3.35490300e-01, 8.35028243e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 2.28651387e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.70092372e-02, 9.29557342e-02, 2.70092372e-02, 1.31373032e-01,\n",
      "        9.45783175e-02, 0.00000000e+00, 4.15193262e-02, 2.70092372e-02,\n",
      "        0.00000000e+00, 3.45867900e-02, 2.70092372e-02, 1.46556581e-01,\n",
      "        1.60278254e-01, 2.70092372e-02, 4.16957981e-02, 0.00000000e+00,\n",
      "        4.15199169e-02, 3.33711177e-02, 0.00000000e+00, 1.03702306e-01,\n",
      "        9.45289364e-02, 5.97061166e-02, 6.45425494e-02, 8.09585055e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.70092372e-02, 8.83991304e-02, 5.04016403e-02, 1.88146283e-01,\n",
      "        1.69625232e-01, 0.00000000e+00, 3.33707748e-02, 0.00000000e+00,\n",
      "        1.97719187e-02, 1.09116235e-01, 1.16288542e-01, 1.16204832e-01,\n",
      "        1.59434398e-01, 2.70092372e-02, 3.33707748e-02, 0.00000000e+00,\n",
      "        2.44291715e-02, 1.75169921e-01, 8.02604341e-02, 6.22727594e-02,\n",
      "        9.47675312e-02, 0.00000000e+00, 4.92365102e-02, 1.30912688e-02,\n",
      "        0.00000000e+00, 8.50684795e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.58743396e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.97724586e-02, 1.06273491e-01, 3.51877794e-02, 1.78832000e-02,\n",
      "        0.00000000e+00, 8.50684795e-02, 5.52218749e-02, 4.97669780e-02,\n",
      "        0.00000000e+00, 8.50678977e-02, 5.04019438e-02, 6.22728159e-02,\n",
      "        1.87930238e-01, 4.55864458e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.97719187e-02, 1.35978452e-01, 0.00000000e+00, 9.63969188e-02,\n",
      "        8.95718984e-02, 4.55858223e-02, 3.33707748e-02, 2.44288373e-02],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 4.44623785e-02, 1.47139400e-02, 2.62304998e-02,\n",
      "        3.21595254e-02, 6.78623169e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 6.13789091e-03, 8.38462053e-03, 1.07181925e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.89030890e-02, 1.12103589e-01,\n",
      "        3.02285492e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.20603278e-02, 1.83004195e-02, 8.84099812e-03, 1.05202905e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 3.26465856e-02, 6.98841006e-02, 4.08934516e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 8.41570355e-02, 6.71510422e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.14537094e-02, 6.70363813e-02, 9.01034832e-02,\n",
      "        1.14537094e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 3.02582934e-02, 2.46156871e-02, 9.40582899e-02,\n",
      "        0.00000000e+00, 3.28921430e-03, 1.17898214e-02, 0.00000000e+00,\n",
      "        8.84099812e-03, 5.61204633e-02, 2.78174092e-02, 4.10315522e-02,\n",
      "        9.46471671e-03, 0.00000000e+00, 0.00000000e+00, 1.28250107e-02,\n",
      "        4.49318380e-03, 1.17704807e-02, 8.38462053e-03, 9.93207160e-02,\n",
      "        7.63665944e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        4.49318380e-03, 1.70654759e-02, 1.33569360e-01, 5.79174308e-02,\n",
      "        2.70282465e-02, 7.16157161e-02, 2.52264390e-02, 0.00000000e+00,\n",
      "        1.57641540e-02, 2.30689544e-02, 1.40418245e-01, 3.36763989e-02,\n",
      "        1.33528599e-02, 0.00000000e+00, 0.00000000e+00, 4.96781896e-03,\n",
      "        3.56608893e-02, 7.62361327e-02, 3.74450818e-02, 1.26635561e-02,\n",
      "        2.19644937e-02, 2.80007801e-02, 2.57116551e-02, 2.32170464e-02,\n",
      "        0.00000000e+00, 6.27470697e-02, 1.00072438e-01, 9.10103908e-02,\n",
      "        0.00000000e+00, 3.40653831e-02, 2.85728850e-02, 0.00000000e+00,\n",
      "        2.95548364e-02, 9.54272136e-02, 7.68753378e-02, 6.08286682e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.53118299e-02,\n",
      "        1.10856094e-01, 9.35237329e-01, 1.38845774e-01, 0.00000000e+00],\n",
      "       [6.13803160e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 3.54037285e-01, 0.00000000e+00, 6.74037196e-03,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.00496778e-02,\n",
      "        9.05823606e-02, 2.14456383e-01, 7.67518545e-02, 3.75050799e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.67927631e-01, 3.57582732e-01,\n",
      "        7.75467802e-03, 3.32603967e-03, 1.28760367e-02, 4.61756704e-03,\n",
      "        5.85379929e-03, 2.67335551e-02, 2.94764506e-02, 1.37088911e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.45249104e-02,\n",
      "        7.55300987e-02, 1.77238162e-01, 9.88150498e-02, 1.13568164e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        8.05807718e-02, 3.05478113e-01, 6.21363344e-02, 3.85230284e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 7.98258250e-02, 7.86329606e-02, 4.95734996e-01,\n",
      "        1.33685446e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        4.18201476e-02, 1.31563432e-02, 8.30174114e-03, 1.33724057e-01,\n",
      "        0.00000000e+00, 2.63822040e-01, 1.44199912e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.10328295e-01, 8.62173072e-02, 0.00000000e+00,\n",
      "        7.65003121e-03, 3.78227669e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 3.01164784e-02, 1.75787377e-02, 0.00000000e+00,\n",
      "        2.28124858e-01, 2.13908892e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.40372377e-02,\n",
      "        3.20078527e-02, 0.00000000e+00, 0.00000000e+00, 6.96668522e-03,\n",
      "        3.70147988e-03, 0.00000000e+00, 5.45332007e-02, 1.63081240e-01,\n",
      "        0.00000000e+00, 7.60420770e-02, 1.13342635e-01, 0.00000000e+00,\n",
      "        2.37279746e-02, 5.34266899e-02, 4.61391993e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.05361324e-01, 2.76866303e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.60748956e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 6.41813394e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 7.97348402e-02, 1.67092013e-01, 3.41961147e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.09778762e-01, 2.15290661e-01, 1.20987324e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.91939589e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.79272205e-02,\n",
      "        1.34570253e-01, 5.89598195e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.53410767e-02,\n",
      "        9.53912687e-02, 1.64663070e-01, 3.47303001e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.91920682e-02, 7.37424395e-03, 0.00000000e+00,\n",
      "        0.00000000e+00, 2.14918853e-01, 5.65639629e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        9.97530310e-02, 7.42172580e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.25441198e-02,\n",
      "        8.12409876e-02, 4.88249534e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 2.76425956e-02, 1.60750788e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 9.19331105e-02, 4.41771693e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.35872829e-02, 5.02863047e-02, 3.06506715e-02, 8.29827522e-03,\n",
      "        0.00000000e+00, 7.03272245e-03, 3.70167020e-02, 0.00000000e+00,\n",
      "        4.29899222e-02, 1.02526961e-01, 5.05427414e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.52142252e-02, 3.37327514e-02, 5.33736206e-02,\n",
      "        3.91689514e-02, 6.00238288e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 3.54180720e-02, 0.00000000e+00, 4.88247837e-03,\n",
      "        3.45726060e-02, 8.21564429e-02, 3.16702638e-02, 0.00000000e+00,\n",
      "        5.39820350e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.38284750e-02, 3.14740138e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        6.82453109e-02, 4.24673343e-01, 1.13357963e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 5.09449705e-01, 5.91536241e-02, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 6.47553082e-01, 1.05824991e-01, 0.00000000e+00]])\n",
      " array([[0.        , 0.14139816, 0.05572778, ..., 0.0478785 , 0.04059477,\n",
      "        0.05659013],\n",
      "       [0.        , 0.01579225, 0.03712811, ..., 0.38456508, 0.1313893 ,\n",
      "        0.        ],\n",
      "       [0.        , 0.07198995, 0.0648498 , ..., 0.22081096, 0.14456762,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.01367659, 0.        , 0.02218694, ..., 0.00386584, 0.00273895,\n",
      "        0.        ],\n",
      "       [0.02492494, 0.06320474, 0.03013648, ..., 0.25166646, 0.1510719 ,\n",
      "        0.        ],\n",
      "       [0.1104246 , 0.        , 0.01938026, ..., 0.03539346, 0.00992229,\n",
      "        0.        ]])\n",
      " array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.39124249, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.39124249, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.39124249, 0.        ,\n",
      "        0.        , 0.1123549 , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.1123549 , 0.12265755, 0.04873164, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.39124249, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.26293308, 0.07491159, 0.        ,\n",
      "        0.03226547, 0.13734461, 0.21683043, 0.        , 0.        ,\n",
      "        0.39124249, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.02361971, 0.        , 0.        , 0.39124249, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.1123549 , 0.33261701, 0.        , 0.        , 0.20966166,\n",
      "        0.        , 0.        , 0.0602095 ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.06186699, 0.12111641, 0.05243173,\n",
      "        0.09279004, 0.11240164, 0.        , 0.09279004, 0.05243173,\n",
      "        0.        , 0.08451253, 0.08451253, 0.        , 0.25339985,\n",
      "        0.20020239, 0.20020239, 0.25339985, 0.09279004, 0.05243173,\n",
      "        0.06186699, 0.12111641, 0.05243173, 0.09279004, 0.        ,\n",
      "        0.11240164, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.05497756,\n",
      "        0.32596325, 0.0195068 , 0.        , 0.        , 0.10668508,\n",
      "        0.        , 0.12458836, 0.08303381, 0.48518395, 0.48518395,\n",
      "        0.08303381, 0.        , 0.41270997, 0.19251542, 0.        ,\n",
      "        0.        , 0.0195068 , 0.32596325, 0.05497756, 0.12458836,\n",
      "        0.        , 0.10668508, 0.        ],\n",
      "       [0.01382654, 0.        , 0.01639194, 0.13261553, 0.12160051,\n",
      "        0.0275411 , 0.        , 0.05897319, 0.12021383, 0.02021818,\n",
      "        0.        , 0.12688431, 0.04227671, 0.        , 0.        ,\n",
      "        0.13181   , 0.15946942, 0.        , 0.        , 0.        ,\n",
      "        0.04102656, 0.        , 0.        , 0.38532491, 0.01452364,\n",
      "        0.00587388, 0.00323579, 0.00933596, 0.0063929 , 0.00216598,\n",
      "        0.        , 0.0207676 , 0.01766216, 0.        , 0.        ,\n",
      "        0.17851784, 0.09946762, 0.        , 0.00819499, 0.09319293,\n",
      "        0.06093686, 0.02331788, 0.        , 0.07022369, 0.06608112,\n",
      "        0.        , 0.0086903 , 0.19744086, 0.0281937 , 0.        ,\n",
      "        0.        , 0.01797048, 0.02012863, 0.        , 0.        ,\n",
      "        0.45825102, 0.02377908, 0.00186834, 0.00249152, 0.01393491,\n",
      "        0.0060159 , 0.        , 0.        , 0.017293  , 0.08173688,\n",
      "        0.00489434, 0.01036099, 0.214448  , 0.02711347, 0.01193444,\n",
      "        0.        , 0.08806133, 0.10608408, 0.        , 0.        ,\n",
      "        0.06094136, 0.10906223, 0.        , 0.00822559, 0.22354984,\n",
      "        0.13106309, 0.        , 0.02205045, 0.03180437, 0.01034946,\n",
      "        0.01173877, 0.01312094, 0.36492081, 0.01225268, 0.        ,\n",
      "        0.00980734, 0.01889693, 0.00747415, 0.00242047, 0.00558697,\n",
      "        0.01196003, 0.13035942, 0.        , 0.        , 0.13235633,\n",
      "        0.15267012, 0.        , 0.        , 0.13185772, 0.15555381,\n",
      "        0.        , 0.        , 0.11918536, 0.03958325, 0.02540688,\n",
      "        0.        , 0.18996252, 0.        , 0.        , 0.        ,\n",
      "        0.03901333, 0.09977329, 0.        , 0.00316319, 0.53031345,\n",
      "        0.        , 0.00661323, 0.        , 0.02339016, 0.00622399,\n",
      "        0.00424762, 0.00763359, 0.00434562],\n",
      "       [0.0774475 , 0.12788639, 0.09024171, 0.0534924 , 0.08705939,\n",
      "        0.19217941, 0.20501975, 0.        , 0.06226463, 0.17988485,\n",
      "        0.        , 0.19754734, 0.08343395, 0.12191546, 0.09835095,\n",
      "        0.        , 0.20440127, 0.02018496, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.0984015 , 0.15545514, 0.09094329,\n",
      "        0.        , 0.        , 0.        , 0.05705102, 0.12011745,\n",
      "        0.16883601, 0.06517232, 0.18147939, 0.08916934, 0.06796598,\n",
      "        0.        , 0.05846459, 0.        , 0.        , 0.08635207,\n",
      "        0.05133817, 0.06676491, 0.11035885, 0.34286533, 0.13532729,\n",
      "        0.03652118, 0.04638745, 0.        , 0.11468372, 0.06819981,\n",
      "        0.07969886, 0.        , 0.        , 0.        , 0.0308518 ,\n",
      "        0.35281249, 0.0226594 , 0.04455299, 0.3197851 , 0.        ,\n",
      "        0.        , 0.06237028, 0.04378849, 0.        , 0.12471106,\n",
      "        0.17444507, 0.        , 0.        , 0.02850444, 0.04239807,\n",
      "        0.06201978, 0.23032816, 0.01827021, 0.04761105, 0.09982207,\n",
      "        0.16231981, 0.05854981, 0.18823085, 0.12480027, 0.        ,\n",
      "        0.        , 0.0158974 , 0.0532959 , 0.19295136, 0.04880421,\n",
      "        0.15600304, 0.        , 0.25293681, 0.13328205, 0.11061879,\n",
      "        0.08830749, 0.        , 0.        , 0.02385481, 0.05072172,\n",
      "        0.06593332, 0.        , 0.01414742, 0.03448437, 0.02515136,\n",
      "        0.0394917 , 0.12099506, 0.07611771, 0.15806646, 0.05732042,\n",
      "        0.        , 0.01187182, 0.08838029, 0.20916833, 0.11805202,\n",
      "        0.11998114, 0.        , 0.19075717, 0.        , 0.00887191,\n",
      "        0.09445388, 0.05052429, 0.05641774, 0.06508243, 0.16452482,\n",
      "        0.0387252 , 0.        , 0.        , 0.06353236, 0.        ,\n",
      "        0.09984201, 0.10731632, 0.07824757],\n",
      "       [0.01271705, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.28963793, 0.49326416, 0.06129839, 0.10557843, 0.        ,\n",
      "        0.        , 0.10273849, 0.28902048, 0.19206412, 0.12694751,\n",
      "        0.36702614, 0.01176212, 0.00446232, 0.02415778, 0.0225644 ,\n",
      "        0.51701195, 0.01743077, 0.0132611 , 0.0118565 , 0.01691096,\n",
      "        0.        , 0.00464945, 0.        , 0.02654753, 0.00959844,\n",
      "        0.01619664, 0.03964529, 0.05452198, 0.        , 0.03737266,\n",
      "        0.01456661, 0.07775068, 0.03290842, 0.        , 0.12812154,\n",
      "        0.02663864, 0.04395459, 0.        , 0.        , 0.        ,\n",
      "        0.13277805, 0.29088643, 0.09572327, 0.00982109, 0.02336321,\n",
      "        0.00245361, 0.13775316, 0.20835919, 0.05534081, 0.        ,\n",
      "        0.00990817, 0.02041237, 0.02233452, 0.        , 0.03707572,\n",
      "        0.01549836, 0.01147031, 0.        , 0.03015481, 0.01925653,\n",
      "        0.        , 0.03851228, 0.12622468, 0.05356641, 0.03746815,\n",
      "        0.12423018, 0.03652523, 0.        , 0.02766365, 0.        ,\n",
      "        0.06303381, 0.00540253, 0.0429786 , 0.09477963, 0.12916409,\n",
      "        0.00923696, 0.        , 0.08122191, 0.11315435, 0.02554893,\n",
      "        0.03881391, 0.06265401, 0.00706028, 0.07951907, 0.08472271,\n",
      "        0.0478094 , 0.07459555, 0.02531383, 0.01866957, 0.01429185,\n",
      "        0.        , 0.03834371, 0.00555194, 0.01263049, 0.02856708,\n",
      "        0.05284253, 0.01989953, 0.02671636, 0.02182204, 0.01406942,\n",
      "        0.02918822, 0.00982109, 0.        , 0.01584667, 0.05015791,\n",
      "        0.04529268, 0.08408823, 0.01830202, 0.07177097, 0.01051706,\n",
      "        0.0074515 , 0.02362465, 0.07413299, 0.02507995, 0.07181069,\n",
      "        0.12678698, 0.        , 0.07043081, 0.07091399, 0.12857875,\n",
      "        0.05206863, 0.07718881, 0.10666196],\n",
      "       [0.11880105, 0.04702377, 0.09952182, 0.02303866, 0.15185383,\n",
      "        0.        , 0.05942117, 0.        , 0.03779564, 0.00924754,\n",
      "        0.07698036, 0.04144244, 0.08798678, 0.02515204, 0.03128351,\n",
      "        0.        , 0.07009178, 0.02850503, 0.        , 0.        ,\n",
      "        0.04747176, 0.10473842, 0.01743302, 0.08472747, 0.42581137,\n",
      "        0.06221073, 0.        , 0.07420195, 0.15615583, 0.        ,\n",
      "        0.39242414, 0.        , 0.        , 0.00696785, 0.04620857,\n",
      "        0.23770284, 0.        , 0.23169498, 0.07636804, 0.        ,\n",
      "        0.1560727 , 0.16058682, 0.02493545, 0.01224882, 0.0601182 ,\n",
      "        0.0625215 , 0.06439192, 0.09418316, 0.08215869, 0.08388472,\n",
      "        0.13456362, 0.11167245, 0.12809016, 0.11530878, 0.01709019,\n",
      "        0.18639194, 0.03722815, 0.19582322, 0.22145863, 0.02382659,\n",
      "        0.19391297, 0.13960506, 0.06995042, 0.1605464 , 0.        ,\n",
      "        0.00650377, 0.19524748, 0.30309592, 0.06985403, 0.06740603,\n",
      "        0.11840588, 0.        , 0.08615683, 0.0657886 , 0.01467077,\n",
      "        0.0888344 , 0.0154097 , 0.05718842, 0.04559043, 0.        ,\n",
      "        0.05678804, 0.12684128, 0.04077471, 0.12066346, 0.03854941,\n",
      "        0.0298739 , 0.12504386, 0.06944422, 0.04887639, 0.09174575,\n",
      "        0.11292113, 0.09238527, 0.06971691, 0.03900476, 0.02636801,\n",
      "        0.10883831, 0.        , 0.02092008, 0.02998949, 0.00908834,\n",
      "        0.04653418, 0.10768604, 0.11345015, 0.04470961, 0.11541032,\n",
      "        0.        , 0.01348485, 0.01996417, 0.15930166, 0.09221165,\n",
      "        0.02679063, 0.07618118, 0.        , 0.05763529, 0.01199581,\n",
      "        0.01868431, 0.04001504, 0.03474615, 0.07141127, 0.04419641,\n",
      "        0.0493878 , 0.10263356, 0.02940597, 0.03028689, 0.06407151,\n",
      "        0.        , 0.10338779, 0.27795385],\n",
      "       [0.13224358, 0.14217588, 0.0662808 , 0.03657469, 0.03952413,\n",
      "        0.        , 0.02264241, 0.09218898, 0.0365206 , 0.        ,\n",
      "        0.15991385, 0.23490618, 0.09884939, 0.03399786, 0.        ,\n",
      "        0.03189734, 0.20599944, 0.0805681 , 0.03646546, 0.0414387 ,\n",
      "        0.02354295, 0.        , 0.00827786, 0.10263835, 0.0518298 ,\n",
      "        0.07453324, 0.06098095, 0.07565189, 0.02377305, 0.0652089 ,\n",
      "        0.06506954, 0.        , 0.01148445, 0.04366641, 0.05383123,\n",
      "        0.08885494, 0.06561369, 0.14181527, 0.27790838, 0.04330089,\n",
      "        0.1189144 , 0.        , 0.        , 0.06249459, 0.07424832,\n",
      "        0.18562328, 0.12121662, 0.13979023, 0.        , 0.06662267,\n",
      "        0.05413519, 0.15683155, 0.07691109, 0.08621831, 0.18880869,\n",
      "        0.05049162, 0.        , 0.154812  , 0.13741075, 0.        ,\n",
      "        0.05301051, 0.28694247, 0.19033044, 0.02907684, 0.07199429,\n",
      "        0.0586332 , 0.        , 0.04943712, 0.06134049, 0.10315836,\n",
      "        0.14964912, 0.19557848, 0.        , 0.24902779, 0.16012573,\n",
      "        0.        , 0.00447394, 0.06438852, 0.22115161, 0.10085858,\n",
      "        0.11854574, 0.15221737, 0.        , 0.12846956, 0.12160249,\n",
      "        0.03300095, 0.        , 0.14303985, 0.05786261, 0.19115888,\n",
      "        0.08140348, 0.01009459, 0.04041724, 0.01586086, 0.0864017 ,\n",
      "        0.00725182, 0.        , 0.10074091, 0.07002749, 0.15100902,\n",
      "        0.        , 0.06935058, 0.16220166, 0.06793049, 0.24566841,\n",
      "        0.05666557, 0.        , 0.        , 0.05476567, 0.07576103,\n",
      "        0.23318314, 0.17183445, 0.04637031, 0.        , 0.06170827,\n",
      "        0.15475069, 0.04459607, 0.04246193, 0.        , 0.30971521,\n",
      "        0.08068684, 0.        , 0.        , 0.1311205 , 0.09166834,\n",
      "        0.09209991, 0.05209673, 0.04614094]])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The axis argument to unique is not supported for dtype object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/proj5/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mconsolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj5/lib/python3.6/site-packages/numpy/core/_internal.py\u001b[0m in \u001b[0;36m_view_is_safe\u001b[0;34m(oldtype, newtype)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnewtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moldtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot change data-type for object array.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot change data-type for object array.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-588021cd3361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No existing visual word vocabulary found. Computing one from training images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m  \u001b[0;31m# Larger values will work better (to a point) but be much slower to compute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gtFall2019/computerVision/proj5_v2/proj5_code/student_code.py\u001b[0m in \u001b[0;36mbuild_vocabulary\u001b[0;34m(image_arrays, vocab_size, stride)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m#feat_array = feat_array.reshape((N, dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gtFall2019/computerVision/proj5_v2/proj5_code/student_code.py\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(feature_vectors, k, max_iter)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mnum_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_unique\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mrand_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj5/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# There's no good way to do this for object arrays, etc...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'The axis argument to unique is not supported for dtype {dt}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreshape_uniq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The axis argument to unique is not supported for dtype object"
     ]
    }
   ],
   "source": [
    "print('Using the BAG-OF-SIFT representation for images')\n",
    "\n",
    "vocab_filename = '../data/vocab2.pkl'\n",
    "if not osp.isfile(vocab_filename):\n",
    "    # Construct the vocabulary\n",
    "    print('No existing visual word vocabulary found. Computing one from training images')\n",
    "    vocab_size = 50  # Larger values will work better (to a point) but be much slower to compute\n",
    "    vocab = sc.build_vocabulary(train_image_arrays, vocab_size)\n",
    "    with open(vocab_filename, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "        print('{:s} saved'.format(vocab_filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built our vocabulary of visual words, we will use it to process our training and testing images.\n",
    "\n",
    "You will need to implement two analagous functions to run the cell below\n",
    "\n",
    "**Note: running on the full dataset will take some time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_kmeans_quantize_exact_matches()\" + verify(test_kmeans_quantize_exact_matches))\n",
    "print(\"test_kmeans_quantize_noisy_continuous()\" + verify(test_kmeans_quantize_noisy_continuous))\n",
    "\n",
    "print(\"test_get_bags_of_sifts()\" + verify(test_get_bags_of_sifts))\n",
    "\n",
    "with open(vocab_filename, 'rb') as f:\n",
    "    vocabulary = pickle.load(f)\n",
    "train_image_feats = sc.get_bags_of_sifts(train_image_arrays, vocabulary)\n",
    "test_image_feats = sc.get_bags_of_sifts(test_image_arrays, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2b: Classify each test image by training and using the Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2c: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(train_labels, test_labels, categories, abbr_categories,\n",
    "             predicted_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have seen that a basic classifier as simple as kNN is sufficient to get this classification task done with around 50% accuracy; you may choose to experiment with SVM classifier, which can boost your performance up to 60%, but that's not required for this project.\n",
    "\n",
    "This shows you how things are done in the pre-deep learning era, and the result is, uh, okay. In the next project, you will learn how to implement an actual neural network to do the classification, where 80% ~ 90% accuracies can be achieved with ease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
